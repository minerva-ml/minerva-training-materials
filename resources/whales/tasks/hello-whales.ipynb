{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Minerva Whales problem\n",
    "\n",
    "\n",
    "# Whale recognition\n",
    "In this problem we will reproduce the winning solution to the [Right Whale Recognition challenge from kaggle](https://www.kaggle.com/c/noaa-right-whale-recognition). \n",
    "\n",
    "# The Solution\n",
    "Solution has 3 stages or subproblems:\n",
    "\n",
    "* **Whale head localization**\n",
    "\n",
    "You need to find coordinates of the bounding box with the whale head inside.\n",
    "\n",
    "<img src=\"static/localizer_example.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "* **Whale head keypoint detection**\n",
    "\n",
    "You need to find coordinates of blowtip and blowhead on whale head. They are needed for head alignment.\n",
    "\n",
    "<img src=\"static/aligner_example.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "* **Whale recognition** \n",
    "\n",
    "The original task of whale ID or name classification. All the steps that come before this one are meant to normalize the input and make it easier for the neural network.\n",
    "\n",
    "<img src=\"static/classifier_example.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "# You will learn\n",
    "- How to work with Pytorch framework\n",
    "- How to build a deep neural network\n",
    "- How optimization hyperparameters interact with each other and how to tweak them\n",
    "- How to use augmentation and you will build your own custom pytorch data loader\n",
    "- How to split data into train and validation sets \n",
    "- How to use weight decay for regularization\n",
    "- How weight initialization can make or break your training\n",
    "\n",
    "# How it works\n",
    "You choose the subproblem with use of `--sub_problem` parameter. Its available values are:\n",
    "- `localization`\n",
    "- `alignment`\n",
    "- `classification`\n",
    "\n",
    "All the commands below are written for `localization`.\n",
    "## Dry run mode\n",
    "In dry run mode you can run our pipeline to make sure that everything is working correctly.\n",
    "\n",
    "#### If you work without Neptune:\n",
    "  1. You need the whale data from kaggle:\n",
    "    - download file `imgs.zip` from [Right Whale Recognition challenge site on kaggle](https://www.kaggle.com/c/noaa-right-whale-recognition/data) (you must be logged in to kaggle to do that),\n",
    "    - extract `imgs.zip` to `resources/whales/data/`,\n",
    "    - after that, folder `resources/whales/data/` should contain two elements: file `metadata.csv` and folder `imgs` with images.\n",
    "  2. In `neptune.yaml` file:\n",
    "    - uncomment Local setup paths,\n",
    "    - set `data_dir` as `resources/whales/data/`,\n",
    "    - set `solution_dir` local path in a way you like, e.g. `output/path_to_your_solution`,\n",
    "    - comment Cloud setup paths,\n",
    "    - comment `pip-requirements-file` line.\n",
    "  3. Type:\n",
    "```bash\n",
    "python main.py -- dry_run --problem whales --sub_problem localization\n",
    "```\n",
    "\n",
    "#### If you want to run our pipeline locally and use Neptune to visualize the results:\n",
    "  1. Download the whale data in the same way like above.\n",
    "  2. Edit `neptune.yaml` file in the same way like above.\n",
    "  3. Type:\n",
    "```bash\n",
    "neptune run main.py -- dry_run \\\n",
    "--problem whales --sub_problem localization\n",
    "```\n",
    "\n",
    "#### If you want to run our pipeline on the cloud available through Neptune:\n",
    "  1. In `neptune.yaml` file:\n",
    "    - comment Local setup paths,\n",
    "    - uncomment Cloud setup paths,\n",
    "    - set `data_dir` as `/public/whales`,\n",
    "    - set `solution_dir` local path in a way you like, but with `/output` in the beginning, e.g.  `/output/path_to_your_solution`,\n",
    "    - uncomment `pip-requirements-file` line.\n",
    "  2. Type:\n",
    "```bash\n",
    "neptune send main.py \\\n",
    "--environment pytorch-0.2.0-gpu-py3 \\\n",
    "--worker gcp-gpu-medium \\\n",
    "-- dry_run --problem whales --sub_problem localization\n",
    "```\n",
    "\n",
    "## Submit mode\n",
    "Submit mode is the main Minerva mode where you exchange one step from our pipeline with your own solution and submit it.\n",
    "### Writing your own solution\n",
    "Choose a task, for example `task1.ipynb`. Write your implementation to the task by filling CONFIG dictionary and the body of the solution function according to the instructions:\n",
    "```python\n",
    "CONFIG = {}\n",
    "def solution():\n",
    "    return something\n",
    "```\n",
    "\n",
    "### Submiting\n",
    "Submit your solution by running one of three options:\n",
    "\n",
    "#### Without Neptune:\n",
    "  1. Download whales data as described for the dry run mode.\n",
    "  2. Edit `neptune.yaml` file in the same way like in the dry run mode.\n",
    "  3. Type:\n",
    "```bash\n",
    "python main.py -- submit --problem whales --sub_problem localization \\\n",
    "--task_nr 1 --filepath resources/whales/tasks/task1.ipynb\n",
    "```\n",
    "\n",
    "#### Locally with Neptune monitoring:\n",
    "  1. Download whales data as described for the dry run mode.\n",
    "  2. Edit `neptune.yaml` file in the same way like in the dry run mode.\n",
    "  3. Type:\n",
    "```bash\n",
    "neptune run main.py -- submit \\\n",
    "--problem whales --sub_problem localization --task_nr 1 \\\n",
    "--filepath resources/whales/tasks/task1.ipynb\n",
    "```\n",
    "\n",
    "#### On Neptune's cloud:\n",
    "  1. Edit `neptune.yaml` file in the same way like in the dry run mode.\n",
    "  2. Type:\n",
    "```bash\n",
    "neptune send run_minerva.py \\\n",
    "--environment pytorch-0.2.0-gpu-py3 \\\n",
    "--worker gcp-gpu-medium \\\n",
    "--config config.yaml \\\n",
    "-- submit --problem whales --sub_problem localization --task_nr 1 \\\n",
    "--filepath resources/whales/tasks/task1.ipynb\n",
    "```\n",
    "\n",
    "Then wait for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "64px",
    "width": "255px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
