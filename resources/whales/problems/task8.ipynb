{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Implement pytorch dataset for keypoint detection.\n",
    "\n",
    "Read about custom datasets here:\n",
    "* https://jdhao.github.io/2017/10/23/pytorch-load-data-and-make-batch/\n",
    "\n",
    "Image augmentation is an important part of deep learning pipelines. It artificially increases your training sample by generating transformed versions of images.\n",
    "\n",
    "<img src=\"static/imgaug.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "You can read about it here:\n",
    "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "* https://github.com/aleju/imgaug\n",
    "\n",
    "You should implement the following augmentations:\n",
    "* randomly fliping left and right\n",
    "* randomly fliping up and down\n",
    "* randomly translating by up to 4 pixels\n",
    "* randomly rotating the image by 180 degrees\n",
    "* randomly scaling the image from 1.0 to 1.5\n",
    "\n",
    "This loader apart from reading images and augmenting them is also cropping the input image by using the localizer network outputs: bounding box coordinates.\n",
    "\n",
    "You should use `-s alignment` in the execution command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution\n",
    "Your solution function should be called solution. In this case we leave it for consistency but you don't need to do anything with it. \n",
    "\n",
    "CONFIG is a dictionary with all parameters that you want to pass to your solution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG={},\n",
    "\n",
    "def solution():\n",
    "    \"\"\"\n",
    "    Create your ProbabilityCalibration implementation and\n",
    "    output an instance of that class.\n",
    "    \"\"\"\n",
    "    class DatasetAligner(Dataset):\n",
    "    def __init__(self, X, y, crop_coordinates, img_dirpath, augmentation, target_size, bins_nr):\n",
    "            super().__init__()\n",
    "            self.X = X.reset_index(drop=True)\n",
    "            self.y = y.reset_index(drop=True)\n",
    "            self.crop_coordinates = crop_coordinates\n",
    "            \n",
    "            self.img_dirpath = img_dirpath\n",
    "            self.target_size = target_size\n",
    "            self.bins_nr = bins_nr\n",
    "            self.augmentation = augmentation\n",
    "\n",
    "        def load_image(self, img_name):\n",
    "            \"\"\"\n",
    "            Read image from disk to numpy array\n",
    "            \"\"\"\n",
    "            return img_array\n",
    "\n",
    "        def __len__(self):\n",
    "            \"\"\"\n",
    "            Determine the length of the dataset\n",
    "            \"\"\"\n",
    "            return length\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"\n",
    "            This method should take the image filepath at X[index] and targets at y[index] and \n",
    "            preprocess them. Use your aligner_preprocessing function.\n",
    "            \n",
    "            Xi_tensor: is a torch.FloatTensor for image\n",
    "            yi_tensors: is a torch.LongTensor for targets it's shape should be 1 x k where k is the number of outputs\n",
    "            \"\"\"\n",
    "            return Xi_tensor, yi_tensors\n",
    "\n",
    "    return DatasetLocalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aligner_preprocessing(img, target, crop_coordinates, augmentation, target_size, bins_nr):\n",
    "    \"\"\"\n",
    "    Run augmentations and transformations on image and target\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_image, processed_target = crop_image_and_adjust_target(img, target, crop_coordinates)\n",
    "    \n",
    "    if augmentation:\n",
    "        \"\"\"\n",
    "        Run augmentations on Image (and target if needed)       \n",
    "        \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Transform coordinates to bin numbers as explained below and normalize the image\n",
    "    \"\"\"\n",
    "    processed_target = bin_quantizer(processed_target, (height, width), bins_nr)\n",
    "    processed_image = normalize_img(processed_image)\n",
    "    return processed_image, processed_target\n",
    "\n",
    "def crop_image_and_adjust_target(img, target, crop_coordinates):\n",
    "    \"\"\"\n",
    "    crop image by using localization network predictions. \n",
    "    Remember to adjust the keypoint positions to the cropped image\n",
    "    \"\"\"\n",
    "    return cropped_image, adjusted_target\n",
    "\n",
    "def bin_quantizer(coordinates, shape, bins_nr):\n",
    "    \"\"\"\n",
    "    Quantize the height and width and transform coordinates to bin numbers\n",
    "    \"\"\"\n",
    "    return binned_coordinates\n",
    "\n",
    "def normalize_img(img):\n",
    "    mean = [0.28201905, 0.37246801, 0.42341868]\n",
    "    std = [0.13609867, 0.12380088, 0.13325344]\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalize Image\n",
    "    \"\"\"\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "64px",
    "width": "255px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
